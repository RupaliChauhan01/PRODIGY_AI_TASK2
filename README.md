# Task-02: Image Generation with Pre-trained Models ğŸ¨ğŸ§ 

This project demonstrates image generation using **pre-trained generative models** such as **DALLÂ·E-mini** and **Stable Diffusion**. With the power of deep learning and transformers, this tool can turn natural language prompts into high-quality images.

### ğŸ” Objective
To explore and implement generative AI models capable of converting text prompts into visual content using open-source tools and pre-trained models.

---

### ğŸ› ï¸ Technologies Used
- Python ğŸ
- Hugging Face ğŸ¤— Transformers & Diffusers
- Stable Diffusion (via `diffusers` library)
- PyTorch

---

### ğŸš€ How It Works
1. Set up Python environment in VS Code
2. Install required libraries: `transformers`, `diffusers`, `torch`
3. Authenticate with Hugging Face token
4. Enter a text prompt
5. The model generates and saves an image based on the prompt

---

### ğŸ“¦ Installation

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install diffusers transformers accelerate# PRODIGY_AI_TASK2
Task-02: Image Generation with Pre-trained Models is a generative Al project that demonstrates how to generate high-quality images from simple text prompts using powerful, publicly available pre-trained models like Stable Diffusion and DALL-E-mini.  
